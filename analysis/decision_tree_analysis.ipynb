{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Originally, I'm testing kmeans algorithm. The dataset I used here are raw text so we need to do some processing first. The function used to load and parse this dataset is in another file called health_news_parser which contains two function to load the data for testing for kmeans and also decision tree model. Since the raw data is text, we need to apply the TDIF feature extractor to convert words into frequency which is a numerical data that can be consumed by the ML algorithms. Since the number of features is high ~ 30000 ish, and the data is very sparse which is around ~ 0.99, it is impossible to visualize how each feature affect the hypothesis at this point. We will now skip to the analysis part after applying dimensionality reduction and collecting the result. The results load into this notebook are output from code in another file.\n",
    "\n",
    "We will explore the importance of each features later after training the decision tree."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:57.709393Z",
     "start_time": "2023-07-05T07:44:56.946024Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from health_news_parser import load_health_news_for_decision_tree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = \"../output/decision_tree/\"\n",
    "df_each = []\n",
    "for filename in os.listdir(path):\n",
    "    f = os.path.join(path, filename)\n",
    "    if os.path.isfile(f) and (\"2\" in f or \"5\" in f):\n",
    "        temp = pd.read_csv(f)\n",
    "        temp = temp[temp.name.apply(lambda x: x != \"name\")]\n",
    "        df_each.append((temp, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:57.715291Z",
     "start_time": "2023-07-05T07:44:57.710567Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metrics for scoring dimensionality reduction results. Can choose to give different eight to reduction time, accuracy and trainnig time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def score(reduc_time, accuracy, train_time, red_w = 200, ac_w = 1, train_w = 20):\n",
    "    return (accuracy ** ac_w)*(red_w/int(reduc_time + 1) + train_w/int(train_time + 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:57.717470Z",
     "start_time": "2023-07-05T07:44:57.715824Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "red_w = 10\n",
    "ac_w = 10\n",
    "train_w = 10\n",
    "included_cols = [\"name\", \"filename\", \"original_shape\", \"transformed_shape\", \"params\", \"reduction_time\", \"accuracy\", \"train_time\", \"score_series\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:57.719606Z",
     "start_time": "2023-07-05T07:44:57.717996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(columns=included_cols)\n",
    "collected_all_df = pd.DataFrame(columns=included_cols)\n",
    "for res in df_each:\n",
    "    res_copy = res[0].copy()\n",
    "    res_copy[\"filename\"] = res[1]\n",
    "    score_series = res_copy[res_copy.name != \"Nothing\"][[\"reduction_time\", \"train_time\", \"accuracy\"]].apply(lambda x: score(x[\"reduction_time\"], x[\"accuracy\"], red_w, ac_w, train_w), axis=1)\n",
    "    res_copy_score = res_copy.copy()\n",
    "    res_copy_score[\"score_series\"] = score_series\n",
    "    out_df = pd.concat([out_df, res_copy_score])\n",
    "    max_ind = res_copy_score.groupby(by=[\"original_shape\"])[\"score_series\"].idxmax()\n",
    "    collected = res_copy_score.iloc[max_ind][[\"name\", \"filename\", \"original_shape\", \"transformed_shape\", \"params\", \"reduction_time\", \"accuracy\", \"train_time\", \"score_series\"]]\n",
    "    collected_all_df = pd.concat([collected_all_df, collected])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:57.729268Z",
     "start_time": "2023-07-05T07:44:57.723769Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are the results of each dimensionality algorithm. One of the columns is the column for descrbing accuracy. As we can see here, for the decision tree model, the sparse JL transform performs the best."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      name  original_shape transformed_shape  \\\nfilename                                                                       \n2        0   extremely sparse JL transform   (7521, 15826)      (7721, 4041)   \n         1   extremely sparse JL transform   (7521, 15826)      (7721, 3907)   \n         2   extremely sparse JL transform   (7521, 15826)      (7721, 2020)   \n         3   extremely sparse JL transform   (7521, 15826)      (7721, 1953)   \n         4   extremely sparse JL transform   (7521, 15826)       (7721, 404)   \n         5   extremely sparse JL transform   (7521, 15826)       (7721, 390)   \n         6   extremely sparse JL transform   (7521, 15826)       (7721, 224)   \n         7   extremely sparse JL transform   (7521, 15826)       (7721, 217)   \n         8             sparse JL transform   (7521, 15826)      (7721, 1582)   \n         9             sparse JL transform   (7521, 15826)      (7721, 1582)   \n         10            sparse JL transform   (7521, 15826)      (7721, 7189)   \n         11            sparse JL transform   (7521, 15826)      (7721, 5526)   \n         12            sparse JL transform   (7521, 15826)       (7721, 287)   \n         13            sparse JL transform   (7521, 15826)       (7721, 221)   \n         14            sparse JL transform   (7521, 15826)        (7721, 88)   \n         15            sparse JL transform   (7521, 15826)        (7721, 68)   \n         16                   JL transform   (7521, 15826)      (7721, 1582)   \n         17                   JL transform   (7521, 15826)      (7721, 1582)   \n         18                   JL transform   (7521, 15826)      (7721, 7189)   \n         19                   JL transform   (7521, 15826)      (7721, 5526)   \n         20                   JL transform   (7521, 15826)       (7721, 287)   \n         21                   JL transform   (7521, 15826)       (7721, 221)   \n         22                   JL transform   (7521, 15826)        (7721, 88)   \n         23                   JL transform   (7521, 15826)        (7721, 68)   \n         24                            PCA   (7521, 15826)        (7721, 77)   \n         25                        Nothing   (7521, 15826)     (7721, 15826)   \n5        0   extremely sparse JL transform  (18920, 34042)     (19420, 4746)   \n         1   extremely sparse JL transform  (18920, 34042)     (19420, 4602)   \n         2   extremely sparse JL transform  (18920, 34042)     (19420, 2373)   \n         3   extremely sparse JL transform  (18920, 34042)     (19420, 2301)   \n         4   extremely sparse JL transform  (18920, 34042)      (19420, 474)   \n         5   extremely sparse JL transform  (18920, 34042)      (19420, 460)   \n         6   extremely sparse JL transform  (18920, 34042)      (19420, 263)   \n         7   extremely sparse JL transform  (18920, 34042)      (19420, 255)   \n         8             sparse JL transform  (18920, 34042)    (19420, 28759)   \n         9             sparse JL transform  (18920, 34042)    (19420, 22104)   \n         10            sparse JL transform  (18920, 34042)     (19420, 7189)   \n         11            sparse JL transform  (18920, 34042)     (19420, 5526)   \n         12            sparse JL transform  (18920, 34042)      (19420, 287)   \n         13            sparse JL transform  (18920, 34042)      (19420, 221)   \n         14            sparse JL transform  (18920, 34042)       (19420, 88)   \n         15            sparse JL transform  (18920, 34042)       (19420, 68)   \n         16                   JL transform  (18920, 34042)    (19420, 28759)   \n         17                   JL transform  (18920, 34042)    (19420, 22104)   \n         18                   JL transform  (18920, 34042)     (19420, 7189)   \n         19                   JL transform  (18920, 34042)     (19420, 5526)   \n         20                   JL transform  (18920, 34042)      (19420, 287)   \n         21                   JL transform  (18920, 34042)      (19420, 221)   \n         22                   JL transform  (18920, 34042)       (19420, 88)   \n         23                   JL transform  (18920, 34042)       (19420, 68)   \n         24                            PCA  (18920, 34042)      (19420, 194)   \n         25                        Nothing  (18920, 34042)    (19420, 34042)   \n\n                                                  params  reduction_time  \\\nfilename                                                                   \n2        0                      {'ep': 0.05, 'de': 0.05}        0.499629   \n         1                       {'ep': 0.05, 'de': 0.1}        0.556030   \n         2                       {'ep': 0.1, 'de': 0.05}        0.488768   \n         3                        {'ep': 0.1, 'de': 0.1}        0.466752   \n         4                       {'ep': 0.5, 'de': 0.05}        0.467465   \n         5                        {'ep': 0.5, 'de': 0.1}        0.462496   \n         6                       {'ep': 0.9, 'de': 0.05}        0.462231   \n         7                        {'ep': 0.9, 'de': 0.1}        0.462833   \n         8                      {'ep': 0.05, 'de': 0.05}        2.004327   \n         9                       {'ep': 0.05, 'de': 0.1}        1.984776   \n         10                      {'ep': 0.1, 'de': 0.05}        7.600143   \n         11                       {'ep': 0.1, 'de': 0.1}        5.803091   \n         12                      {'ep': 0.5, 'de': 0.05}        0.510463   \n         13                       {'ep': 0.5, 'de': 0.1}        0.504962   \n         14                      {'ep': 0.9, 'de': 0.05}        0.285085   \n         15                       {'ep': 0.9, 'de': 0.1}        0.285990   \n         16                     {'ep': 0.05, 'de': 0.05}        1.875658   \n         17                      {'ep': 0.05, 'de': 0.1}        1.879715   \n         18                      {'ep': 0.1, 'de': 0.05}        7.641705   \n         19                       {'ep': 0.1, 'de': 0.1}        5.689541   \n         20                      {'ep': 0.5, 'de': 0.05}        0.487102   \n         21                       {'ep': 0.5, 'de': 0.1}        0.452248   \n         22                      {'ep': 0.9, 'de': 0.05}        0.264045   \n         23                       {'ep': 0.9, 'de': 0.1}        0.209704   \n         24   {'n_components': 77, 'svd_solver': 'auto'}        4.410252   \n         25                                           {}        0.000198   \n5        0                      {'ep': 0.05, 'de': 0.05}        5.082444   \n         1                       {'ep': 0.05, 'de': 0.1}        5.141505   \n         2                       {'ep': 0.1, 'de': 0.05}        4.712962   \n         3                        {'ep': 0.1, 'de': 0.1}        4.155604   \n         4                       {'ep': 0.5, 'de': 0.05}        4.018365   \n         5                        {'ep': 0.5, 'de': 0.1}        3.978315   \n         6                       {'ep': 0.9, 'de': 0.05}        3.838281   \n         7                        {'ep': 0.9, 'de': 0.1}        3.829837   \n         8                      {'ep': 0.05, 'de': 0.05}      141.830719   \n         9                       {'ep': 0.05, 'de': 0.1}      105.447106   \n         10                      {'ep': 0.1, 'de': 0.05}       32.969807   \n         11                       {'ep': 0.1, 'de': 0.1}       25.320903   \n         12                      {'ep': 0.5, 'de': 0.05}        2.270777   \n         13                       {'ep': 0.5, 'de': 0.1}        2.091690   \n         14                      {'ep': 0.9, 'de': 0.05}        1.570569   \n         15                       {'ep': 0.9, 'de': 0.1}        1.766735   \n         16                     {'ep': 0.05, 'de': 0.05}      128.494039   \n         17                      {'ep': 0.05, 'de': 0.1}      101.825684   \n         18                      {'ep': 0.1, 'de': 0.05}       33.780918   \n         19                       {'ep': 0.1, 'de': 0.1}       25.169705   \n         20                      {'ep': 0.5, 'de': 0.05}        2.276009   \n         21                       {'ep': 0.5, 'de': 0.1}        2.022318   \n         22                      {'ep': 0.9, 'de': 0.05}        1.411484   \n         23                       {'ep': 0.9, 'de': 0.1}        1.696405   \n         24  {'n_components': 194, 'svd_solver': 'auto'}       39.313781   \n         25                                           {}        0.000457   \n\n             accuracy  train_time  score_series  \nfilename                                         \n2        0      0.990    4.184810     10.688152  \n         1      0.935    6.166727      6.034854  \n         2      0.765    4.725257      0.811269  \n         3      0.960    2.924579      7.857113  \n         4      0.625    1.888037      0.107486  \n         5      0.620    2.470510      0.099190  \n         6      0.600    1.309810      0.071460  \n         7      0.585    1.009665      0.055477  \n         8      0.980    3.095135      4.209163  \n         9      0.985    3.169277      5.861798  \n         10     0.980    4.187765      2.506928  \n         11     0.985    3.866942      2.996030  \n         12     0.980    2.807974      9.656315  \n         13     0.965    2.698205      8.276063  \n         14     0.915    2.385611      4.861403  \n         15     0.895    2.297592      3.897454  \n         16     0.870   14.673104      1.693796  \n         17     0.925   14.589144      3.126698  \n         18     0.960   33.292576      2.039827  \n         19     0.940   29.221159      1.876992  \n         20     0.855    5.833775      2.467242  \n         21     0.840    5.065625      2.067015  \n         22     0.765    3.363958      0.811269  \n         23     0.735    2.968241      0.543781  \n         24     0.985    2.446190      3.282607  \n         25     0.985   15.881628           NaN  \n5        0      0.716   33.192836      0.123400  \n         1      0.602   39.720911      0.021785  \n         2      0.816   14.426370      0.499756  \n         3      0.422   32.232944      0.000684  \n         4      0.300    7.455794      0.000023  \n         5      0.254    9.169791      0.000005  \n         6      0.264    3.908615      0.000007  \n         7      0.242    4.250398      0.000003  \n         8      0.982   32.052107      1.574910  \n         9      0.978   28.716505      1.531069  \n         10     0.968   19.986369      1.532278  \n         11     0.968   19.297996      1.591212  \n         12     0.926   10.262342      2.388058  \n         13     0.926    9.428983      2.388058  \n         14     0.850    7.869968      1.342325  \n         15     0.828    7.453368      1.032695  \n         16     0.800  202.560610      0.203549  \n         17     0.804  177.586481      0.216275  \n         18     0.784  100.200348      0.185317  \n         19     0.744   88.124119      0.114473  \n         20     0.644   19.398569      0.063211  \n         21     0.560   17.071901      0.015625  \n         22     0.514   11.263186      0.008776  \n         23     0.484   10.120562      0.004810  \n         24     0.958   15.654374      1.346616  \n         25     0.978  107.896455           NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>name</th>\n      <th>original_shape</th>\n      <th>transformed_shape</th>\n      <th>params</th>\n      <th>reduction_time</th>\n      <th>accuracy</th>\n      <th>train_time</th>\n      <th>score_series</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"26\" valign=\"top\">2</th>\n      <th>0</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 4041)</td>\n      <td>{'ep': 0.05, 'de': 0.05}</td>\n      <td>0.499629</td>\n      <td>0.990</td>\n      <td>4.184810</td>\n      <td>10.688152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 3907)</td>\n      <td>{'ep': 0.05, 'de': 0.1}</td>\n      <td>0.556030</td>\n      <td>0.935</td>\n      <td>6.166727</td>\n      <td>6.034854</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 2020)</td>\n      <td>{'ep': 0.1, 'de': 0.05}</td>\n      <td>0.488768</td>\n      <td>0.765</td>\n      <td>4.725257</td>\n      <td>0.811269</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 1953)</td>\n      <td>{'ep': 0.1, 'de': 0.1}</td>\n      <td>0.466752</td>\n      <td>0.960</td>\n      <td>2.924579</td>\n      <td>7.857113</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 404)</td>\n      <td>{'ep': 0.5, 'de': 0.05}</td>\n      <td>0.467465</td>\n      <td>0.625</td>\n      <td>1.888037</td>\n      <td>0.107486</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 390)</td>\n      <td>{'ep': 0.5, 'de': 0.1}</td>\n      <td>0.462496</td>\n      <td>0.620</td>\n      <td>2.470510</td>\n      <td>0.099190</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 224)</td>\n      <td>{'ep': 0.9, 'de': 0.05}</td>\n      <td>0.462231</td>\n      <td>0.600</td>\n      <td>1.309810</td>\n      <td>0.071460</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>extremely sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 217)</td>\n      <td>{'ep': 0.9, 'de': 0.1}</td>\n      <td>0.462833</td>\n      <td>0.585</td>\n      <td>1.009665</td>\n      <td>0.055477</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 1582)</td>\n      <td>{'ep': 0.05, 'de': 0.05}</td>\n      <td>2.004327</td>\n      <td>0.980</td>\n      <td>3.095135</td>\n      <td>4.209163</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 1582)</td>\n      <td>{'ep': 0.05, 'de': 0.1}</td>\n      <td>1.984776</td>\n      <td>0.985</td>\n      <td>3.169277</td>\n      <td>5.861798</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 7189)</td>\n      <td>{'ep': 0.1, 'de': 0.05}</td>\n      <td>7.600143</td>\n      <td>0.980</td>\n      <td>4.187765</td>\n      <td>2.506928</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 5526)</td>\n      <td>{'ep': 0.1, 'de': 0.1}</td>\n      <td>5.803091</td>\n      <td>0.985</td>\n      <td>3.866942</td>\n      <td>2.996030</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 287)</td>\n      <td>{'ep': 0.5, 'de': 0.05}</td>\n      <td>0.510463</td>\n      <td>0.980</td>\n      <td>2.807974</td>\n      <td>9.656315</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 221)</td>\n      <td>{'ep': 0.5, 'de': 0.1}</td>\n      <td>0.504962</td>\n      <td>0.965</td>\n      <td>2.698205</td>\n      <td>8.276063</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 88)</td>\n      <td>{'ep': 0.9, 'de': 0.05}</td>\n      <td>0.285085</td>\n      <td>0.915</td>\n      <td>2.385611</td>\n      <td>4.861403</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>sparse JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 68)</td>\n      <td>{'ep': 0.9, 'de': 0.1}</td>\n      <td>0.285990</td>\n      <td>0.895</td>\n      <td>2.297592</td>\n      <td>3.897454</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 1582)</td>\n      <td>{'ep': 0.05, 'de': 0.05}</td>\n      <td>1.875658</td>\n      <td>0.870</td>\n      <td>14.673104</td>\n      <td>1.693796</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 1582)</td>\n      <td>{'ep': 0.05, 'de': 0.1}</td>\n      <td>1.879715</td>\n      <td>0.925</td>\n      <td>14.589144</td>\n      <td>3.126698</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 7189)</td>\n      <td>{'ep': 0.1, 'de': 0.05}</td>\n      <td>7.641705</td>\n      <td>0.960</td>\n      <td>33.292576</td>\n      <td>2.039827</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 5526)</td>\n      <td>{'ep': 0.1, 'de': 0.1}</td>\n      <td>5.689541</td>\n      <td>0.940</td>\n      <td>29.221159</td>\n      <td>1.876992</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 287)</td>\n      <td>{'ep': 0.5, 'de': 0.05}</td>\n      <td>0.487102</td>\n      <td>0.855</td>\n      <td>5.833775</td>\n      <td>2.467242</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 221)</td>\n      <td>{'ep': 0.5, 'de': 0.1}</td>\n      <td>0.452248</td>\n      <td>0.840</td>\n      <td>5.065625</td>\n      <td>2.067015</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 88)</td>\n      <td>{'ep': 0.9, 'de': 0.05}</td>\n      <td>0.264045</td>\n      <td>0.765</td>\n      <td>3.363958</td>\n      <td>0.811269</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>JL transform</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 68)</td>\n      <td>{'ep': 0.9, 'de': 0.1}</td>\n      <td>0.209704</td>\n      <td>0.735</td>\n      <td>2.968241</td>\n      <td>0.543781</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>PCA</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 77)</td>\n      <td>{'n_components': 77, 'svd_solver': 'auto'}</td>\n      <td>4.410252</td>\n      <td>0.985</td>\n      <td>2.446190</td>\n      <td>3.282607</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Nothing</td>\n      <td>(7521, 15826)</td>\n      <td>(7721, 15826)</td>\n      <td>{}</td>\n      <td>0.000198</td>\n      <td>0.985</td>\n      <td>15.881628</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"26\" valign=\"top\">5</th>\n      <th>0</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 4746)</td>\n      <td>{'ep': 0.05, 'de': 0.05}</td>\n      <td>5.082444</td>\n      <td>0.716</td>\n      <td>33.192836</td>\n      <td>0.123400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 4602)</td>\n      <td>{'ep': 0.05, 'de': 0.1}</td>\n      <td>5.141505</td>\n      <td>0.602</td>\n      <td>39.720911</td>\n      <td>0.021785</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 2373)</td>\n      <td>{'ep': 0.1, 'de': 0.05}</td>\n      <td>4.712962</td>\n      <td>0.816</td>\n      <td>14.426370</td>\n      <td>0.499756</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 2301)</td>\n      <td>{'ep': 0.1, 'de': 0.1}</td>\n      <td>4.155604</td>\n      <td>0.422</td>\n      <td>32.232944</td>\n      <td>0.000684</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 474)</td>\n      <td>{'ep': 0.5, 'de': 0.05}</td>\n      <td>4.018365</td>\n      <td>0.300</td>\n      <td>7.455794</td>\n      <td>0.000023</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 460)</td>\n      <td>{'ep': 0.5, 'de': 0.1}</td>\n      <td>3.978315</td>\n      <td>0.254</td>\n      <td>9.169791</td>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 263)</td>\n      <td>{'ep': 0.9, 'de': 0.05}</td>\n      <td>3.838281</td>\n      <td>0.264</td>\n      <td>3.908615</td>\n      <td>0.000007</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>extremely sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 255)</td>\n      <td>{'ep': 0.9, 'de': 0.1}</td>\n      <td>3.829837</td>\n      <td>0.242</td>\n      <td>4.250398</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 28759)</td>\n      <td>{'ep': 0.05, 'de': 0.05}</td>\n      <td>141.830719</td>\n      <td>0.982</td>\n      <td>32.052107</td>\n      <td>1.574910</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 22104)</td>\n      <td>{'ep': 0.05, 'de': 0.1}</td>\n      <td>105.447106</td>\n      <td>0.978</td>\n      <td>28.716505</td>\n      <td>1.531069</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 7189)</td>\n      <td>{'ep': 0.1, 'de': 0.05}</td>\n      <td>32.969807</td>\n      <td>0.968</td>\n      <td>19.986369</td>\n      <td>1.532278</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 5526)</td>\n      <td>{'ep': 0.1, 'de': 0.1}</td>\n      <td>25.320903</td>\n      <td>0.968</td>\n      <td>19.297996</td>\n      <td>1.591212</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 287)</td>\n      <td>{'ep': 0.5, 'de': 0.05}</td>\n      <td>2.270777</td>\n      <td>0.926</td>\n      <td>10.262342</td>\n      <td>2.388058</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 221)</td>\n      <td>{'ep': 0.5, 'de': 0.1}</td>\n      <td>2.091690</td>\n      <td>0.926</td>\n      <td>9.428983</td>\n      <td>2.388058</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 88)</td>\n      <td>{'ep': 0.9, 'de': 0.05}</td>\n      <td>1.570569</td>\n      <td>0.850</td>\n      <td>7.869968</td>\n      <td>1.342325</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>sparse JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 68)</td>\n      <td>{'ep': 0.9, 'de': 0.1}</td>\n      <td>1.766735</td>\n      <td>0.828</td>\n      <td>7.453368</td>\n      <td>1.032695</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 28759)</td>\n      <td>{'ep': 0.05, 'de': 0.05}</td>\n      <td>128.494039</td>\n      <td>0.800</td>\n      <td>202.560610</td>\n      <td>0.203549</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 22104)</td>\n      <td>{'ep': 0.05, 'de': 0.1}</td>\n      <td>101.825684</td>\n      <td>0.804</td>\n      <td>177.586481</td>\n      <td>0.216275</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 7189)</td>\n      <td>{'ep': 0.1, 'de': 0.05}</td>\n      <td>33.780918</td>\n      <td>0.784</td>\n      <td>100.200348</td>\n      <td>0.185317</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 5526)</td>\n      <td>{'ep': 0.1, 'de': 0.1}</td>\n      <td>25.169705</td>\n      <td>0.744</td>\n      <td>88.124119</td>\n      <td>0.114473</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 287)</td>\n      <td>{'ep': 0.5, 'de': 0.05}</td>\n      <td>2.276009</td>\n      <td>0.644</td>\n      <td>19.398569</td>\n      <td>0.063211</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 221)</td>\n      <td>{'ep': 0.5, 'de': 0.1}</td>\n      <td>2.022318</td>\n      <td>0.560</td>\n      <td>17.071901</td>\n      <td>0.015625</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 88)</td>\n      <td>{'ep': 0.9, 'de': 0.05}</td>\n      <td>1.411484</td>\n      <td>0.514</td>\n      <td>11.263186</td>\n      <td>0.008776</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>JL transform</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 68)</td>\n      <td>{'ep': 0.9, 'de': 0.1}</td>\n      <td>1.696405</td>\n      <td>0.484</td>\n      <td>10.120562</td>\n      <td>0.004810</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>PCA</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 194)</td>\n      <td>{'n_components': 194, 'svd_solver': 'auto'}</td>\n      <td>39.313781</td>\n      <td>0.958</td>\n      <td>15.654374</td>\n      <td>1.346616</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Nothing</td>\n      <td>(18920, 34042)</td>\n      <td>(19420, 34042)</td>\n      <td>{}</td>\n      <td>0.000457</td>\n      <td>0.978</td>\n      <td>107.896455</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = out_df.groupby(by=\"filename\", group_keys=True).apply(lambda x: x[:])\n",
    "all[[\"name\", \"original_shape\", \"transformed_shape\", \"params\", \"reduction_time\", \"accuracy\", \"train_time\", \"score_series\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:57.741350Z",
     "start_time": "2023-07-05T07:44:57.730255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        original_shape  transformed_shape  \\\nfilename name                                                               \n2        extremely sparse JL transform               1                  1   \n5        sparse JL transform                         1                  1   \n\n                                        params  reduction_time  accuracy  \\\nfilename name                                                              \n2        extremely sparse JL transform       1               1         1   \n5        sparse JL transform                 1               1         1   \n\n                                        train_time  score_series  \nfilename name                                                     \n2        extremely sparse JL transform           1             1  \n5        sparse JL transform                     1             1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>original_shape</th>\n      <th>transformed_shape</th>\n      <th>params</th>\n      <th>reduction_time</th>\n      <th>accuracy</th>\n      <th>train_time</th>\n      <th>score_series</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <th>extremely sparse JL transform</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <th>sparse JL transform</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_all_df.groupby([\"filename\", \"name\"]).count().sort_values(by=\"original_shape\").groupby(level=0).tail(1).sort_values(by=\"filename\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:57.747244Z",
     "start_time": "2023-07-05T07:44:57.742245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['00', '000', '0000', ..., 'zzukaz', 'zzzzz', 'zâ'], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, names = load_health_news_for_decision_tree(5, \"../data/health+news+in+twitter/Health-Tweets/\")\n",
    "names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:59.103226Z",
     "start_time": "2023-07-05T07:44:57.747595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= data.training_data, data.testing_data, data.training_label, data.testing_label\n",
    "rf = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:44:59.105304Z",
     "start_time": "2023-07-05T07:44:59.103744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.653482Z",
     "start_time": "2023-07-05T07:44:59.106518Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "00         6.689091e-06\n000        1.428233e-04\n0000       3.327497e-07\n000th      2.505835e-05\n007        2.116010e-06\n               ...     \nzzgrrgf    1.850145e-07\nzznvii     6.474405e-07\nzzukaz     9.798430e-07\nzzzzz      7.910921e-10\nzâ         8.750825e-07\nLength: 34042, dtype: float64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.Series(rf.feature_importances_, index=names)\n",
    "std = np.std([importances for tree in rf.estimators_], axis=0)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.681604Z",
     "start_time": "2023-07-05T07:46:40.654003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news    0.081064\n",
      "in      0.066856\n",
      "ws      0.055910\n",
      "khne    0.050941\n",
      "bit     0.040637\n",
      "http    0.040252\n",
      "to      0.033668\n",
      "at      0.031416\n",
      "ly      0.029917\n",
      "com     0.028703\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(importances.sort_values(ascending=False).iloc[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.689061Z",
     "start_time": "2023-07-05T07:46:40.680619Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are the most important features (words) that can be used to classify each news site."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA31UlEQVR4nO3dfVzV9f3/8eeRq9NKUEFBChS6kkalQSv0i+hWOLXWhVu6lX5XYmP0S+XkpmjmpBqtmTGTi1TIm982o6X71hZL8IpZskxE3RppWyjOOBk6JbsAhM/vj76edXaOFwfRo28e99vtc9vO+7w+n/N63+bs2ftzZbMsyxIAAAAueD383QAAAAC6BsEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAwR6O8GukpHR4c+/PBD9ezZUzabzd/tAAAAdAnLsvTJJ58oOjpaPXqcfE3OmGD34YcfKiYmxt9tAAAAnBX79u3TZZdddtIaY4Jdz549JX056dDQUD93AwAA0DWam5sVExPjyjonY0ywO376NTQ0lGAHAACMczqXmnHzBAAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGCIQH83cD4YOOv1c/p7e54ae05/DwAAdA+dWrErLCxUXFyc7Ha7kpKStGnTppPWV1VVKSkpSXa7XfHx8SouLvaoyc/P19VXX62LLrpIMTExys7O1hdffNGZ9gAAALoln4NdWVmZpk+frjlz5qi2tlapqakaPXq0GhoavNbX19drzJgxSk1NVW1trWbPnq2pU6dq1apVrppf//rXmjVrlubNm6e6ujqVlJSorKxMOTk5nZ8ZAABAN2OzLMvyZYebbrpJN9xwg4qKilxjCQkJuvPOO5WXl+dRP3PmTL322muqq6tzjWVmZmrHjh2qrq6WJP2///f/VFdXp3Xr1rlqHnnkEW3ZsuWUq4HHNTc3KywsTEeOHFFoaKgvU+JULAAAOG/5knF8WrFrbW1VTU2N0tPT3cbT09O1efNmr/tUV1d71I8aNUpbt25VW1ubJOm//uu/VFNToy1btkiSPvjgA5WXl2vs2BMHoJaWFjU3N7ttAAAA3ZlPN080NTWpvb1dkZGRbuORkZFyOp1e93E6nV7rjx07pqamJvXv318TJkzQxx9/rP/6r/+SZVk6duyYfvzjH2vWrFkn7CUvL0/z58/3pX0AAACjdermCZvN5vbZsiyPsVPVf3V848aNevLJJ1VYWKht27Zp9erV+sMf/qDHH3/8hMfMycnRkSNHXNu+ffs6MxUAAABj+LRiFxERoYCAAI/VuQMHDnisyh0XFRXltT4wMFDh4eGSpLlz52rixInKyMiQJF177bX69NNP9eCDD2rOnDnq0cMzf4aEhCgkJMSX9gEAAIzm04pdcHCwkpKSVFlZ6TZeWVmpoUOHet0nJSXFo76iokLJyckKCgqSJH322Wce4S0gIECWZcnHezsAAAC6LZ9PxTocDi1btkylpaWqq6tTdna2GhoalJmZKenLU6STJk1y1WdmZmrv3r1yOByqq6tTaWmpSkpKNGPGDFfN7bffrqKiIr300kuqr69XZWWl5s6dq+985zsKCAjogmkCAACYz+c3T4wfP14HDx5Ubm6uGhsblZiYqPLycg0YMECS1NjY6PZMu7i4OJWXlys7O1sFBQWKjo7WokWLNG7cOFfNo48+KpvNpkcffVT79+9X3759dfvtt+vJJ5/sgikCAAB0Dz4/x+58xXPsAACAic7ac+wAAABw/iLYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIToV7AoLCxUXFye73a6kpCRt2rTppPVVVVVKSkqS3W5XfHy8iouL3b4fMWKEbDabxzZ27NjOtAcAANAt+RzsysrKNH36dM2ZM0e1tbVKTU3V6NGj1dDQ4LW+vr5eY8aMUWpqqmprazV79mxNnTpVq1atctWsXr1ajY2Nru2vf/2rAgIC9L3vfa/zMwMAAOhmbJZlWb7scNNNN+mGG25QUVGRaywhIUF33nmn8vLyPOpnzpyp1157TXV1da6xzMxM7dixQ9XV1V5/Iz8/X4899pgaGxt18cUXn1Zfzc3NCgsL05EjRxQaGurLlDRw1us+1Z+pPU+xEgkAAE6PLxnHpxW71tZW1dTUKD093W08PT1dmzdv9rpPdXW1R/2oUaO0detWtbW1ed2npKREEyZMOO1QBwAAACnQl+Kmpia1t7crMjLSbTwyMlJOp9PrPk6n02v9sWPH1NTUpP79+7t9t2XLFv31r39VSUnJSXtpaWlRS0uL63Nzc7MvUwEAADBOp26esNlsbp8ty/IYO1W9t3Hpy9W6xMREfeMb3zhpD3l5eQoLC3NtMTExp9s+AACAkXwKdhEREQoICPBYnTtw4IDHqtxxUVFRXusDAwMVHh7uNv7ZZ5/ppZdeUkZGxil7ycnJ0ZEjR1zbvn37fJkKAACAcXwKdsHBwUpKSlJlZaXbeGVlpYYOHep1n5SUFI/6iooKJScnKygoyG385ZdfVktLi+67775T9hISEqLQ0FC3DQAAoDvz+VSsw+HQsmXLVFpaqrq6OmVnZ6uhoUGZmZmSvlxJmzRpkqs+MzNTe/fulcPhUF1dnUpLS1VSUqIZM2Z4HLukpER33nmnx0oeAAAATs2nmyckafz48Tp48KByc3PV2NioxMRElZeXa8CAAZKkxsZGt2faxcXFqby8XNnZ2SooKFB0dLQWLVqkcePGuR139+7devPNN1VRUXGGUwIAAOiefH6O3fmK59gBAAATnbXn2AEAAOD8RbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAzh8yvFcGHi7RoAAJiPFTsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwRKeCXWFhoeLi4mS325WUlKRNmzadtL6qqkpJSUmy2+2Kj49XcXGxR83hw4f10EMPqX///rLb7UpISFB5eXln2gMAAOiWfA52ZWVlmj59uubMmaPa2lqlpqZq9OjRamho8FpfX1+vMWPGKDU1VbW1tZo9e7amTp2qVatWuWpaW1t16623as+ePXrllVe0a9cuLV26VJdeemnnZwYAANDNBPq6w8KFCzV58mRlZGRIkvLz87VmzRoVFRUpLy/Po764uFixsbHKz8+XJCUkJGjr1q1asGCBxo0bJ0kqLS3VoUOHtHnzZgUFBUmSBgwY0Nk5AQAAdEs+rdi1traqpqZG6enpbuPp6enavHmz132qq6s96keNGqWtW7eqra1NkvTaa68pJSVFDz30kCIjI5WYmKif//znam9vP2EvLS0tam5udtsAAAC6M5+CXVNTk9rb2xUZGek2HhkZKafT6XUfp9Pptf7YsWNqamqSJH3wwQd65ZVX1N7ervLycj366KN65pln9OSTT56wl7y8PIWFhbm2mJgYX6YCAABgnE7dPGGz2dw+W5blMXaq+q+Od3R0qF+/flqyZImSkpI0YcIEzZkzR0VFRSc8Zk5Ojo4cOeLa9u3b15mpAAAAGMOna+wiIiIUEBDgsTp34MABj1W546KiorzWBwYGKjw8XJLUv39/BQUFKSAgwFWTkJAgp9Op1tZWBQcHexw3JCREISEhvrQPAABgNJ9W7IKDg5WUlKTKykq38crKSg0dOtTrPikpKR71FRUVSk5Odt0oMWzYMP39739XR0eHq2b37t3q37+/11AHAAAATz6finU4HFq2bJlKS0tVV1en7OxsNTQ0KDMzU9KXp0gnTZrkqs/MzNTevXvlcDhUV1en0tJSlZSUaMaMGa6aH//4xzp48KCmTZum3bt36/XXX9fPf/5zPfTQQ10wRQAAgO7B58edjB8/XgcPHlRubq4aGxuVmJio8vJy1+NJGhsb3Z5pFxcXp/LycmVnZ6ugoEDR0dFatGiR61EnkhQTE6OKigplZ2fruuuu06WXXqpp06Zp5syZXTBFAACA7sFmHb+T4QLX3NyssLAwHTlyRKGhoT7tO3DW62epK+/2PDX2nP6e1D3mCACAiXzJOLwrFgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBCB/m4A6CoDZ71+Tn9vz1Njz+nvAQBwKqzYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgiMDO7FRYWKhf/vKXamxs1Ne//nXl5+crNTX1hPVVVVVyOBx69913FR0drZ/+9KfKzMx0fb98+XLdf//9Hvt9/vnnstvtnWkRMNLAWa+f09/b89TYc/p7AIAz4/OKXVlZmaZPn645c+aotrZWqampGj16tBoaGrzW19fXa8yYMUpNTVVtba1mz56tqVOnatWqVW51oaGhamxsdNsIdQAAAKfP5xW7hQsXavLkycrIyJAk5efna82aNSoqKlJeXp5HfXFxsWJjY5Wfny9JSkhI0NatW7VgwQKNGzfOVWez2RQVFdXJaQAAAMCnFbvW1lbV1NQoPT3dbTw9PV2bN2/2uk91dbVH/ahRo7R161a1tbW5xo4ePaoBAwbosssu02233aba2lpfWgMAAOj2fAp2TU1Nam9vV2RkpNt4ZGSknE6n132cTqfX+mPHjqmpqUmSNGjQIC1fvlyvvfaaVq5cKbvdrmHDhun9998/YS8tLS1qbm522wAAALqzTt0Va7PZ3D5bluUxdqr6r47ffPPNuu+++3T99dcrNTVVL7/8sq666io999xzJzxmXl6ewsLCXFtMTExnpgIAAGAMn4JdRESEAgICPFbnDhw44LEqd1xUVJTX+sDAQIWHh3tvqkcP3XjjjSddscvJydGRI0dc2759+3yZCgAAgHF8CnbBwcFKSkpSZWWl23hlZaWGDh3qdZ+UlBSP+oqKCiUnJysoKMjrPpZlafv27erfv/8JewkJCVFoaKjbBgAA0J35fCrW4XBo2bJlKi0tVV1dnbKzs9XQ0OB6Ll1OTo4mTZrkqs/MzNTevXvlcDhUV1en0tJSlZSUaMaMGa6a+fPna82aNfrggw+0fft2TZ48Wdu3b3d71h0AAABOzufHnYwfP14HDx5Ubm6uGhsblZiYqPLycg0YMECS1NjY6PZMu7i4OJWXlys7O1sFBQWKjo7WokWL3B51cvjwYT344INyOp0KCwvTkCFD9Kc//Unf+MY3umCKAAAA3UOn3jyRlZWlrKwsr98tX77cYywtLU3btm074fGeffZZPfvss51pBQAAAP+Hd8UCAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYolPBrrCwUHFxcbLb7UpKStKmTZtOWl9VVaWkpCTZ7XbFx8eruLj4hLUvvfSSbDab7rzzzs60BgAA0G0F+rpDWVmZpk+frsLCQg0bNkzPP/+8Ro8erb/97W+KjY31qK+vr9eYMWM0ZcoUvfjii3rrrbeUlZWlvn37aty4cW61e/fu1YwZM5Samtr5GQG4oA2c9fo5/b09T409p78HAGeTzyt2Cxcu1OTJk5WRkaGEhATl5+crJiZGRUVFXuuLi4sVGxur/Px8JSQkKCMjQw888IAWLFjgVtfe3q57771X8+fPV3x8fOdmAwAA0I35tGLX2tqqmpoazZo1y208PT1dmzdv9rpPdXW10tPT3cZGjRqlkpIStbW1KSgoSJKUm5urvn37avLkyac8tStJLS0tamlpcX1ubm72ZSoA4DesSgI4W3xasWtqalJ7e7siIyPdxiMjI+V0Or3u43Q6vdYfO3ZMTU1NkqS33npLJSUlWrp06Wn3kpeXp7CwMNcWExPjy1QAAACM06mbJ2w2m9tny7I8xk5Vf3z8k08+0X333aelS5cqIiLitHvIycnRkSNHXNu+fft8mAEAAIB5fDoVGxERoYCAAI/VuQMHDnisyh0XFRXltT4wMFDh4eF69913tWfPHt1+++2u7zs6Or5sLjBQu3bt0uWXX+5x3JCQEIWEhPjSPgAAgNF8WrELDg5WUlKSKisr3cYrKys1dOhQr/ukpKR41FdUVCg5OVlBQUEaNGiQ/vKXv2j79u2u7Tvf+Y5Gjhyp7du3c4oVAADgNPn8uBOHw6GJEycqOTlZKSkpWrJkiRoaGpSZmSnpy1Ok+/fv14oVKyRJmZmZWrx4sRwOh6ZMmaLq6mqVlJRo5cqVkiS73a7ExES33+jVq5ckeYwDAADgxHwOduPHj9fBgweVm5urxsZGJSYmqry8XAMGDJAkNTY2qqGhwVUfFxen8vJyZWdnq6CgQNHR0Vq0aJHHM+wAAABwZnwOdpKUlZWlrKwsr98tX77cYywtLU3btm077eN7OwYAAABOjnfFAgAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhgj0dwMAAPMMnPX6Of29PU+NPae/B5yvWLEDAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEb54AAMBH5/rNGhJv18DpYcUOAADAEJ0KdoWFhYqLi5PdbldSUpI2bdp00vqqqiolJSXJbrcrPj5excXFbt+vXr1aycnJ6tWrly6++GINHjxY//M//9OZ1gAAALotn4NdWVmZpk+frjlz5qi2tlapqakaPXq0GhoavNbX19drzJgxSk1NVW1trWbPnq2pU6dq1apVrpo+ffpozpw5qq6u1s6dO3X//ffr/vvv15o1azo/MwAAgG7G52C3cOFCTZ48WRkZGUpISFB+fr5iYmJUVFTktb64uFixsbHKz89XQkKCMjIy9MADD2jBggWumhEjRuiuu+5SQkKCLr/8ck2bNk3XXXed3nzzzc7PDAAAoJvxKdi1traqpqZG6enpbuPp6enavHmz132qq6s96keNGqWtW7eqra3No96yLK1bt067du3S8OHDfWkPAACgW/Pprtimpia1t7crMjLSbTwyMlJOp9PrPk6n02v9sWPH1NTUpP79+0uSjhw5oksvvVQtLS0KCAhQYWGhbr311hP20tLSopaWFtfn5uZmX6YCAABgnE497sRms7l9tizLY+xU9f853rNnT23fvl1Hjx7VunXr5HA4FB8frxEjRng9Zl5enubPn9+Z9gEAwCnwSJcLk0/BLiIiQgEBAR6rcwcOHPBYlTsuKirKa31gYKDCw8NdYz169NAVV1whSRo8eLDq6uqUl5d3wmCXk5Mjh8Ph+tzc3KyYmBhfpgMAAGAUn66xCw4OVlJSkiorK93GKysrNXToUK/7pKSkeNRXVFQoOTlZQUFBJ/wty7LcTrX+p5CQEIWGhrptAAAA3ZnPp2IdDocmTpyo5ORkpaSkaMmSJWpoaFBmZqakL1fS9u/frxUrVkiSMjMztXjxYjkcDk2ZMkXV1dUqKSnRypUrXcfMy8tTcnKyLr/8crW2tqq8vFwrVqw44Z22AAAA8ORzsBs/frwOHjyo3NxcNTY2KjExUeXl5RowYIAkqbGx0e2ZdnFxcSovL1d2drYKCgoUHR2tRYsWady4ca6aTz/9VFlZWfrnP/+piy66SIMGDdKLL76o8ePHd8EUAQAAuodO3TyRlZWlrKwsr98tX77cYywtLU3btm074fGeeOIJPfHEE51pBQAAAP+nU8EOAADgQmfinb+delcsAAAAzj8EOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMESngl1hYaHi4uJkt9uVlJSkTZs2nbS+qqpKSUlJstvtio+PV3Fxsdv3S5cuVWpqqnr37q3evXvrlltu0ZYtWzrTGgAAQLflc7ArKyvT9OnTNWfOHNXW1io1NVWjR49WQ0OD1/r6+nqNGTNGqampqq2t1ezZszV16lStWrXKVbNx40Z9//vf14YNG1RdXa3Y2Filp6dr//79nZ8ZAABAN+NzsFu4cKEmT56sjIwMJSQkKD8/XzExMSoqKvJaX1xcrNjYWOXn5yshIUEZGRl64IEHtGDBAlfNr3/9a2VlZWnw4MEaNGiQli5dqo6ODq1bt67zMwMAAOhmfAp2ra2tqqmpUXp6utt4enq6Nm/e7HWf6upqj/pRo0Zp69atamtr87rPZ599pra2NvXp0+eEvbS0tKi5udltAwAA6M58CnZNTU1qb29XZGSk23hkZKScTqfXfZxOp9f6Y8eOqampyes+s2bN0qWXXqpbbrnlhL3k5eUpLCzMtcXExPgyFQAAAON06uYJm83m9tmyLI+xU9V7G5ekp59+WitXrtTq1atlt9tPeMycnBwdOXLEte3bt8+XKQAAABgn0JfiiIgIBQQEeKzOHThwwGNV7rioqCiv9YGBgQoPD3cbX7BggX7+859r7dq1uu66607aS0hIiEJCQnxpHwAAwGg+rdgFBwcrKSlJlZWVbuOVlZUaOnSo131SUlI86isqKpScnKygoCDX2C9/+Us9/vjjeuONN5ScnOxLWwAAAFAnTsU6HA4tW7ZMpaWlqqurU3Z2thoaGpSZmSnpy1OkkyZNctVnZmZq7969cjgcqqurU2lpqUpKSjRjxgxXzdNPP61HH31UpaWlGjhwoJxOp5xOp44ePdoFUwQAAOgefDoVK0njx4/XwYMHlZubq8bGRiUmJqq8vFwDBgyQJDU2Nro90y4uLk7l5eXKzs5WQUGBoqOjtWjRIo0bN85VU1hYqNbWVn33u991+6158+bpZz/7WSenBgAA0L34HOwkKSsrS1lZWV6/W758ucdYWlqatm3bdsLj7dmzpzNtAAAA4Ct4VywAAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhCHYAAACGINgBAAAYgmAHAABgCIIdAACAIQh2AAAAhiDYAQAAGIJgBwAAYAiCHQAAgCEIdgAAAIYg2AEAABiCYAcAAGAIgh0AAIAhOhXsCgsLFRcXJ7vdrqSkJG3atOmk9VVVVUpKSpLdbld8fLyKi4vdvn/33Xc1btw4DRw4UDabTfn5+Z1pCwAAoFvzOdiVlZVp+vTpmjNnjmpra5WamqrRo0eroaHBa319fb3GjBmj1NRU1dbWavbs2Zo6dapWrVrlqvnss88UHx+vp556SlFRUZ2fDQAAQDfmc7BbuHChJk+erIyMDCUkJCg/P18xMTEqKiryWl9cXKzY2Fjl5+crISFBGRkZeuCBB7RgwQJXzY033qhf/vKXmjBhgkJCQjo/GwAAgG7Mp2DX2tqqmpoapaenu42np6dr8+bNXveprq72qB81apS2bt2qtrY2H9v9t5aWFjU3N7ttAAAA3ZlPwa6pqUnt7e2KjIx0G4+MjJTT6fS6j9Pp9Fp/7NgxNTU1+djuv+Xl5SksLMy1xcTEdPpYAAAAJujUzRM2m83ts2VZHmOnqvc27oucnBwdOXLEte3bt6/TxwIAADBBoC/FERERCggI8FidO3DggMeq3HFRUVFe6wMDAxUeHu5ju/8WEhLC9XgAAABf4dOKXXBwsJKSklRZWek2XllZqaFDh3rdJyUlxaO+oqJCycnJCgoK8rFdAAAAnIjPp2IdDoeWLVum0tJS1dXVKTs7Ww0NDcrMzJT05SnSSZMmueozMzO1d+9eORwO1dXVqbS0VCUlJZoxY4arprW1Vdu3b9f27dvV2tqq/fv3a/v27fr73//eBVMEAADoHnw6FStJ48eP18GDB5Wbm6vGxkYlJiaqvLxcAwYMkCQ1Nja6PdMuLi5O5eXlys7OVkFBgaKjo7Vo0SKNGzfOVfPhhx9qyJAhrs8LFizQggULlJaWpo0bN57B9AAAALoPn4OdJGVlZSkrK8vrd8uXL/cYS0tL07Zt2054vIEDB7puqAAAAEDn8K5YAAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEAQ7AAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQBDsAAABDEOwAAAAMQbADAAAwBMEOAADAEJ0KdoWFhYqLi5PdbldSUpI2bdp00vqqqiolJSXJbrcrPj5excXFHjWrVq3SNddco5CQEF1zzTX63e9+15nWAAAAui2fg11ZWZmmT5+uOXPmqLa2VqmpqRo9erQaGhq81tfX12vMmDFKTU1VbW2tZs+eralTp2rVqlWumurqao0fP14TJ07Ujh07NHHiRN1zzz16++23Oz8zAACAbsbnYLdw4UJNnjxZGRkZSkhIUH5+vmJiYlRUVOS1vri4WLGxscrPz1dCQoIyMjL0wAMPaMGCBa6a/Px83XrrrcrJydGgQYOUk5Ojb33rW8rPz+/0xAAAALobn4Jda2urampqlJ6e7jaenp6uzZs3e92nurrao37UqFHaunWr2traTlpzomMCAADAU6AvxU1NTWpvb1dkZKTbeGRkpJxOp9d9nE6n1/pjx46pqalJ/fv3P2HNiY4pSS0tLWppaXF9PnLkiCSpubnZlylJkjpaPvN5nzPRmR7PFHPseszx7GCOXY85dr1zPT+JOZ4NF8ocj+9jWdYpa30KdsfZbDa3z5ZleYydqv4/x309Zl5enubPn+8xHhMTc+LGzxNh+f7u4OxjjmZgjmZgjmZgjmY4kzl+8sknCgsLO2mNT8EuIiJCAQEBHitpBw4c8FhxOy4qKsprfWBgoMLDw09ac6JjSlJOTo4cDofrc0dHhw4dOqTw8PCTBsKu0tzcrJiYGO3bt0+hoaFn/ff8gTmagTmagTmagTma4VzP0bIsffLJJ4qOjj5lrU/BLjg4WElJSaqsrNRdd93lGq+srNQdd9zhdZ+UlBT9/ve/dxurqKhQcnKygoKCXDWVlZXKzs52qxk6dOgJewkJCVFISIjbWK9evXyZTpcIDQ019g/ucczRDMzRDMzRDMzRDOdyjqdaqTvO51OxDodDEydOVHJyslJSUrRkyRI1NDQoMzNT0pcrafv379eKFSskSZmZmVq8eLEcDoemTJmi6upqlZSUaOXKla5jTps2TcOHD9cvfvEL3XHHHXr11Ve1du1avfnmm762BwAA0G35HOzGjx+vgwcPKjc3V42NjUpMTFR5ebkGDBggSWpsbHR7pl1cXJzKy8uVnZ2tgoICRUdHa9GiRRo3bpyrZujQoXrppZf06KOPau7cubr88stVVlamm266qQumCAAA0D106uaJrKwsZWVlef1u+fLlHmNpaWnatm3bSY/53e9+V9/97nc7045fhISEaN68eR6ng03CHM3AHM3AHM3AHM1wPs/RZp3OvbMAAAA473XqXbEAAAA4/xDsAAAADEGwAwAAMATBDgAAwBAEOwCA3/3zn//U/v37/d3GWfHNb35Thw8f9hhvbm7WN7/5zXPfEIxGsDtD3v7PivPbG2+84fbw64KCAg0ePFg/+MEP9K9//cuPnXWtY8eOae3atXr++ef1ySefSJI+/PBDHT161M+ddY34+HgdPHjQY/zw4cOKj4/3Q0fwVUdHh3JzcxUWFqYBAwYoNjZWvXr10uOPP66Ojg5/t9dlNm7cqNbWVo/xL774Qps2bfJDR13vZz/7mfbu3evvNs6q/fv36+WXX9bixYu1aNEit+18wuNOfPCLX/xCAwcO1Pjx4yVJ99xzj1atWqWoqCiVl5fr+uuv93OHXWP37t3auHGjDhw44PGX62OPPeanrrrOtddeq1/84hcaM2aM/vKXv+jGG2+Uw+HQ+vXrlZCQoBdeeMHfLZ6xvXv36tvf/rYaGhrU0tKi3bt3Kz4+XtOnT9cXX3yh4uJif7d4xnr06CGn06l+/fq5jX/00UeKjY1VS0uLnzrrWrt27dJzzz2nuro62Ww2DRo0SA8//LCuvvpqf7d2xnJyclRSUqL58+dr2LBhsixLb731ln72s59pypQpevLJJ/3d4hnZuXOnJGnw4MFav369+vTp4/quvb1db7zxhp5//nnt2bPHTx12naSkJO3YsUNpaWmaPHmy7r77btntdn+31WVeeOEFZWZmKjg42OOd9DabTR988IEfu/sPFk5bXFyc9dZbb1mWZVkVFRVWr169rDVr1liTJ0+2br31Vj931zWWLFliBQQEWJGRkdb1119vDR482LUNGTLE3+11iYsvvtiqr6+3LMuy5s2bZ40bN86yLMuqqamxIiMj/dhZ17njjjus++67z2ppabEuueQS6x//+IdlWZa1ceNG64orrvBzd2fm1VdftV599VXLZrNZK1ascH1+9dVXrdWrV1sPPfSQddVVV/m7zS7x29/+1goMDLRuvvlmKzs728rOzrZSUlKswMBA6+WXX/Z3e2esf//+1quvvuox/r//+79WdHS0HzrqWjabzerRo4fVo0cPy2azeWxf+9rXrJKSEn+32WV27NhhTZ8+3erXr5/Vq1cvKzMz09qyZYu/2+oSl112mfXEE09Y7e3t/m7llAh2PrDb7VZDQ4NlWZY1depU68EHH7Qsy7J27dpl9erVy5+tdZnY2Fjrqaee8ncbZ1Xv3r2td99917Isyxo2bJj1/PPPW5ZlWfX19dZFF13kz9a6THh4uPXee+9ZlmW5BTsT5nj8H4re/mEZHBxsXXXVVdbvf/97f7fZJeLi4qy5c+d6jD/22GNWXFycHzrqWiEhIdauXbs8xt977z3Lbrf7oaOutWfPHqu+vt6y2WzWO++8Y+3Zs8e1ffjhh9axY8f83eJZ0dbWZq1evdq6/fbbraCgICsxMdHKz8+3Dh8+7O/WOq1Pnz7W3//+d3+3cVq4xs4HvXv31r59+yR9eZ3WLbfcIkmyLEvt7e3+bK3L/Otf/9L3vvc9f7dxVg0bNkwOh0OPP/64tmzZorFjx0r68hT0ZZdd5ufuukZHR4fXP5P//Oc/1bNnTz901HU6OjrU0dGh2NhY1+UCx7eWlhbt2rVLt912m7/b7BJOp1OTJk3yGL/vvvvkdDr90FHXuv7667V48WKP8cWLFxtxacuAAQM0cOBAdXR0KDk5WZ9++qnq6uq0Y8cOvfPOO3r99df12muv+bvNLtfR0aHW1la1tLTIsiz16dNHRUVFiomJUVlZmb/b65TJkyfrt7/9rb/bOC2deldsd3X33XfrBz/4ga688kodPHhQo0ePliRt375dV1xxhZ+76xrf+973VFFRoczMTH+3ctYUFBTooYce0iuvvKKioiJdeumlkqQ//vGP+va3v+3n7rrGrbfeqvz8fC1ZskTSl9eAHD16VPPmzdOYMWP83F3XqK+v93cLZ92IESO0adMmj79f3nzzTaWmpvqpq67z9NNPa+zYsVq7dq1SUlJks9m0efNm7du3T+Xl5f5ur8vU19frrrvu0s6dO2Wz2WT936Xtx6/TMmVhoKamRi+88IJWrlypkJAQTZo0SQUFBa4/v88884ymTp3quk79QpKXl6fbbrtNb7zxhq699loFBQW5fb9w4UI/deaJmyd80NbWpl/96lfat2+ffvjDH2rIkCGSpPz8fF1yySXKyMjwc4dnLi8vTwsXLtTYsWO9/uGdOnWqnzrrOvfee6/S0tI0YsQIXXXVVf5u56z48MMPNXLkSAUEBOj9999XcnKy3n//fUVEROhPf/qTxw0HF4pFixbpwQcflN1uP+WdaCb8WS0uLtZjjz2me+65RzfffLMk6c9//rN++9vfav78+YqOjnbVfuc73/FXm53W0NCgwMBAFRQU6L333pNlWbrmmmuUlZWlY8eOKTY21t8tdonbb79dAQEBWrp0qeLj4/X222/r0KFDeuSRR7RgwQIjQvp1112nv/3tbxo1apSmTJnimvNXffzxx4qMjLwg73h+/PHHNW/ePF199dWKjIz0uHli/fr1fuzOHcEObuLi4k743Xl3508n/ehHP1JVVZXef/99RUZGKi0tzRX0Bg0a5O/2usznn3+ulStXatu2bero6NANN9yge++9VxdddJG/W+u0uLg4bd26VeHh4d3iz2qPHqd3tYzNZrsgV30CAgLU2Njo8S8aBw8eVL9+/S7IOXkTERGh9evX67rrrlNYWJi2bNmiq6++WuvXr9cjjzyi2tpaf7d4xh5//HE98MADrjMgpundu7eeffZZ/fCHP/R3K6dEsPNBdHS0RowYoREjRigtLc2Ixw10Z06nUxs3btTGjRtVVVWl3bt3q1+/fmpsbPR3a/DRf57awoXhRI+s2bt3r6655hp9+umnfuqsa/Xu3Vs1NTWKj4/X5ZdfrmXLlmnkyJH6xz/+oWuvvVafffaZv1vsFIfDcdq159Opys6IiorSpk2bdOWVV/q7lVPiGjsfPPPMM6qqqtLChQuVmZnpWu05HvQSEhL83WKnHL+R4OKLLz7p/1FtNpueeeaZc9jZ2dWzZ0/17t1bvXv3Vq9evRQYGKioqCh/t9VlTH8eoSSVlJTo2Wef1fvvvy9JuvLKKzV9+nQjLouQpBUrVmj8+PEKCQlxG29tbdVLL73k9caKC8Hxv2dsNpsee+wxfe1rX3N9197errfffluDBw/2U3ddLzExUTt37lR8fLxuuukmPf300woODtaSJUsu6Idpn+5Kown/wjVt2jQ999xz593DiL1hxa6TPvroI23YsEF/+MMfVFZWdsK7EC8EI0eO1O9+9zv16tVLI0eOPGHd+XYdQWfNnDlTVVVV2rFjhxITEzV8+HClpaVp+PDh6tWrl7/b6xJLly7Vj3/8Y0VERCgqKsrjepBt27b5sbuuMXfuXD377LN6+OGHlZKSIkmqrq7W4sWLNW3aND3xxBN+7vDMmXqq8vjfM1VVVUpJSVFwcLDru+DgYA0cOFAzZsy4IFZHTseaNWv06aef6u6779YHH3yg2267Te+9957Cw8NVVlbGa8UuAHfddZfWr1+v8PBwff3rX/e4/nz16tV+6swTwc5HR48e1Ztvvqmqqipt3LhRtbW1uuaaa5SWlqZnn33W3+3hNPTo0UN9+/ZVdna27rjjjgt2pfVkBgwYoKysLM2cOdPfrZw1EREReu655/T973/fbXzlypV6+OGH1dTU5KfOuk6PHj300UcfqW/fvm7jO3bs0MiRI3Xo0CE/ddY17r//fv3qV79SaGiov1s55w4dOqTevXsbsZrVHdx///0n/f58emMRwc4HN910k3bu3KnExESNGDFCw4cPV2pqqjGrPN3Fjh07XMF806ZNCggIcJ1SHzFihBFBLzQ0VNu3b7+gT/OcSu/evbVlyxaPVZ3du3frG9/4xgX9HuchQ4bIZrNpx44d+vrXv67AwH9fNdPe3q76+np9+9vf1ssvv+zHLgGcjwh2PujTp49sNptuueUWo0JAd7djxw7l5+frxRdfvKBPqX/V5MmTdeONNxr9PMKHH35YQUFBHhdlz5gxQ59//rkKCgr81NmZmz9/vus/H3nkEV1yySWu746fqhw3bpzbKUwAZ9/HH3+sXbt2yWaz6aqrrvJYTT8fcPOEDw4dOqSdO3dq48aNWrt2rebNm6cePXooLS1NI0eONPofoqapra113RG7adMmNTc3a/DgwSe9xvBCcsUVV2ju3Ln685//bNTzCL96c4/NZtOyZctUUVHh9oy3ffv2XbA3FRw3b948SdLAgQM1YcIEj5snAJxbn376qR5++GGtWLHCdTNaQECAJk2apOeee87tBiB/Y8XuDNTU1Gjx4sVGrfR0B71799bRo0d1/fXXu1Zehw8fbtR1PqY+4+10g7cpN/rEx8frnXfeUXh4uNv44cOHdcMNN1yw/zsCF5of/ehHWrt2rRYvXqxhw4ZJ+vINMFOnTtWtt96qoqIiP3f4bwQ7H/znKs8nn3ziCgcjR450vXMU57c//OEPxgU5mOlEz3n76KOPFBsbq5aWFj91BnQvEREReuWVVzRixAi38Q0bNuiee+7Rxx9/7J/GvOBUrA9uvPFGDRkyRGlpaZoyZQrh4AJlygviYa6vvhh+zZo1CgsLc31ub2/XunXrNHDgQD90BnRPn332mSIjIz3G+/Xrd949YJoVOx80NzcT5HBBaG9v1/Lly7Vu3TqvDyg24TSlyY6/SuyrL4w/LigoSAMHDtQzzzzDv6QA58i3vvUthYeHa8WKFbLb7ZK+fG3jf//3f+vQoUNau3atnzv8N1bsfBAaGqrDhw/rlVde0T/+8Q/95Cc/UZ8+fbRt2zZFRkYa+448XHimTZum5cuXa+zYsUpMTORZWReY40E8Li5O77zzjiIiIvzcEdC95efna/To0brssst0/fXXy2azafv27QoJCVFFRYW/23PDip0Pdu7cqW9961vq1auX9uzZo127dik+Pl5z587V3r17tWLFCn+3CEj68nqQFStWaMyYMf5uBWdo3bp1J1x5LS0t9VNXQPfz+eef68UXX9R7770ny7J0zTXX6N5779VFF13k79bcsGLnA4fDofvvv19PP/20evbs6RofPXq0fvCDH/ixM8BdcHCwrrjiCn+3gTOUm5ur+fPnKzk5Wf3792flFfCTvLw8RUZGasqUKW7jpaWl+vjjj8+rt/ywYueDsLAwbdu2TZdffrl69uypHTt2KD4+Xnv37tXVV1+tL774wt8tApKkZ555Rh988IEWL15MGLiA9e/fX08//bQmTpzo71aAbm3gwIH6zW9+o6FDh7qNv/3225owYYLq6+v91JknVux8YLfb1dzc7DG+a9eu8/Lp0+he7r77brfP69ev1x//+Mfz/oXVOLHW1laPf5AAOPecTqf69+/vMd63b181Njb6oaMT6+HvBi4kd9xxh3Jzc9XW1ibpyzvWGhoaNGvWLI0bN87P3aG7CwsLc9vuuusupaWlKSIiwm2cdxtfODIyMvSb3/zG320A3V5MTIzeeustj/G33npL0dHRfujoxFix88GCBQs0ZswY9evXT59//rnS0tLkdDp1880368knn/R3e+jmXnjhBdd/f/HFF3Xfffd5rfvJT35yrlpCJ3z1tWkdHR1asmSJ1q5dq+uuu85j5fU/35ML4OzIyMjQ9OnT1dbWpm9+85uSvryx6ac//akeeeQRP3fnjmvsOmHDhg2qqalRR0eHbrjhBt1yyy3+bglw06tXL7344osezzlzOBxauXLleXfqAP/W3V6bBlwILMvSrFmztGjRIrW2tkr68vKsmTNn6rHHHvNzd+4Idj7i0QO4ELzxxhuaMGGCXnvtNQ0fPlyS9PDDD2vVqlVav369Bg0a5OcOAeDCc/ToUdXV1emiiy7SlVdeqZCQEH+35IFg54P58+crNzf3hI8e+N3vfuenzgBPL730krKyslRRUaHS0lK9+uqr2rBhg6666ip/twYAOEsIdj7g0QO40BQVFSk7O1t9+/bVhg0beLYdABiOmyd8wKMHcD776kX3X9WvXz8NGTJEhYWFrjEuugcAM7Fi54OZM2fqkksu0dy5c/3dCuCBi+4BAKzY+eCLL77g0QM4b23YsMHfLQAA/IwVOx+cbEWEVRAAAOBvBDsAAABD8EoxAAAAQxDsAAAADEGwAwAAMATBDgAAwBAEOwAAAEMQ7AAAAAxBsAMAADAEwQ4AAMAQ/x8exZbKHPy31AAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_im = pd.Series(importances).sort_values(ascending=False).iloc[:10]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "f_im.plot.bar(ax= ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.766859Z",
     "start_time": "2023-07-05T07:46:40.687879Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now compare the results from the decision tree to the kmeans clustering algorithm."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "path = \"../output/news/\"\n",
    "df_each = []\n",
    "for filename in os.listdir(path):\n",
    "    f = os.path.join(path, filename)\n",
    "    if os.path.isfile(f):\n",
    "        temp = pd.read_csv(f)\n",
    "        temp = temp[temp.name.apply(lambda x: x != \"name\")]\n",
    "        df_each.append((temp, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.776888Z",
     "start_time": "2023-07-05T07:46:40.770230Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(columns=included_cols)\n",
    "collected_all_df = pd.DataFrame(columns=included_cols)\n",
    "for res in df_each:\n",
    "    res_copy = res[0].copy()\n",
    "    res_copy[\"filename\"] = res[1]\n",
    "    score_series = res_copy[res_copy.name != \"Nothing\"][[\"reduction_time\", \"train_time\", \"accuracy\"]].apply(lambda x: score(x[\"reduction_time\"], x[\"accuracy\"], red_w, ac_w, train_w), axis=1)\n",
    "    res_copy_score = res_copy.copy()\n",
    "    res_copy_score[\"score_series\"] = score_series\n",
    "    out_df = pd.concat([out_df, res_copy_score])\n",
    "    max_ind = res_copy_score.groupby(by=[\"original_shape\"])[\"score_series\"].idxmax()\n",
    "    collected = res_copy_score.iloc[max_ind][[\"name\", \"filename\", \"original_shape\", \"transformed_shape\", \"params\", \"reduction_time\", \"accuracy\", \"train_time\", \"score_series\"]]\n",
    "    collected_all_df = pd.concat([collected_all_df, collected])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.819080Z",
     "start_time": "2023-07-05T07:46:40.780737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      name  original_shape transformed_shape  \\\nfilename                                                                       \n2        0   extremely sparse JL transform   (6726, 16990)      (6928, 4029)   \n         1   extremely sparse JL transform   (6726, 16990)      (6928, 3894)   \n         2   extremely sparse JL transform   (6726, 16990)      (6928, 2014)   \n         3   extremely sparse JL transform   (6726, 16990)      (6928, 1947)   \n         4   extremely sparse JL transform   (6726, 16990)       (6928, 402)   \n...                                    ...             ...               ...   \n5        21                   JL transform  (23183, 40537)      (23688, 221)   \n         22                   JL transform  (23183, 40537)       (23688, 88)   \n         23                   JL transform  (23183, 40537)       (23688, 68)   \n         24                            PCA  (23183, 40537)      (23688, 236)   \n         25                        Nothing  (23183, 40537)    (23688, 40537)   \n\n                                                  params  reduction_time  \\\nfilename                                                                   \n2        0                      {'ep': 0.05, 'de': 0.05}        0.437593   \n         1                       {'ep': 0.05, 'de': 0.1}        0.423221   \n         2                       {'ep': 0.1, 'de': 0.05}        0.408222   \n         3                        {'ep': 0.1, 'de': 0.1}        0.411041   \n         4                       {'ep': 0.5, 'de': 0.05}        0.408369   \n...                                                  ...             ...   \n5        21                       {'ep': 0.5, 'de': 0.1}        3.132158   \n         22                      {'ep': 0.9, 'de': 0.05}        2.641303   \n         23                       {'ep': 0.9, 'de': 0.1}        2.438814   \n         24  {'n_components': 236, 'svd_solver': 'auto'}       60.950643   \n         25                                           {}        0.000038   \n\n             accuracy  train_time  score_series  \nfilename                                         \n2        0      1.000    0.906473     11.818182  \n         1      0.935    0.715884      6.034854  \n         2      0.975    0.563305      9.174805  \n         3      1.000    0.475363     11.818182  \n         4      0.975    0.544050      9.174805  \n...               ...         ...           ...  \n5        21     0.358    0.581430      0.000149  \n         22     0.318    0.536496      0.000054  \n         23     0.306    0.541322      0.000037  \n         24     0.690    0.578181      0.048486  \n         25     0.622    7.140457           NaN  \n\n[78 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>name</th>\n      <th>original_shape</th>\n      <th>transformed_shape</th>\n      <th>params</th>\n      <th>reduction_time</th>\n      <th>accuracy</th>\n      <th>train_time</th>\n      <th>score_series</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2</th>\n      <th>0</th>\n      <td>extremely sparse JL transform</td>\n      <td>(6726, 16990)</td>\n      <td>(6928, 4029)</td>\n      <td>{'ep': 0.05, 'de': 0.05}</td>\n      <td>0.437593</td>\n      <td>1.000</td>\n      <td>0.906473</td>\n      <td>11.818182</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>extremely sparse JL transform</td>\n      <td>(6726, 16990)</td>\n      <td>(6928, 3894)</td>\n      <td>{'ep': 0.05, 'de': 0.1}</td>\n      <td>0.423221</td>\n      <td>0.935</td>\n      <td>0.715884</td>\n      <td>6.034854</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>extremely sparse JL transform</td>\n      <td>(6726, 16990)</td>\n      <td>(6928, 2014)</td>\n      <td>{'ep': 0.1, 'de': 0.05}</td>\n      <td>0.408222</td>\n      <td>0.975</td>\n      <td>0.563305</td>\n      <td>9.174805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>extremely sparse JL transform</td>\n      <td>(6726, 16990)</td>\n      <td>(6928, 1947)</td>\n      <td>{'ep': 0.1, 'de': 0.1}</td>\n      <td>0.411041</td>\n      <td>1.000</td>\n      <td>0.475363</td>\n      <td>11.818182</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>extremely sparse JL transform</td>\n      <td>(6726, 16990)</td>\n      <td>(6928, 402)</td>\n      <td>{'ep': 0.5, 'de': 0.05}</td>\n      <td>0.408369</td>\n      <td>0.975</td>\n      <td>0.544050</td>\n      <td>9.174805</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>21</th>\n      <td>JL transform</td>\n      <td>(23183, 40537)</td>\n      <td>(23688, 221)</td>\n      <td>{'ep': 0.5, 'de': 0.1}</td>\n      <td>3.132158</td>\n      <td>0.358</td>\n      <td>0.581430</td>\n      <td>0.000149</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>JL transform</td>\n      <td>(23183, 40537)</td>\n      <td>(23688, 88)</td>\n      <td>{'ep': 0.9, 'de': 0.05}</td>\n      <td>2.641303</td>\n      <td>0.318</td>\n      <td>0.536496</td>\n      <td>0.000054</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>JL transform</td>\n      <td>(23183, 40537)</td>\n      <td>(23688, 68)</td>\n      <td>{'ep': 0.9, 'de': 0.1}</td>\n      <td>2.438814</td>\n      <td>0.306</td>\n      <td>0.541322</td>\n      <td>0.000037</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>PCA</td>\n      <td>(23183, 40537)</td>\n      <td>(23688, 236)</td>\n      <td>{'n_components': 236, 'svd_solver': 'auto'}</td>\n      <td>60.950643</td>\n      <td>0.690</td>\n      <td>0.578181</td>\n      <td>0.048486</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Nothing</td>\n      <td>(23183, 40537)</td>\n      <td>(23688, 40537)</td>\n      <td>{}</td>\n      <td>0.000038</td>\n      <td>0.622</td>\n      <td>7.140457</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>78 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all = out_df.groupby(by=\"filename\", group_keys=True).apply(lambda x: x[:])\n",
    "display(all[[\"name\", \"original_shape\", \"transformed_shape\", \"params\", \"reduction_time\", \"accuracy\", \"train_time\", \"score_series\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.819346Z",
     "start_time": "2023-07-05T07:46:40.790545Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the observation, kmeans tends to give better result compared to the decison tree. The overall accuracy is higher for all algorithms. For kmeans, these are the best corresponding best dimensionailty reduction algrithm in terms of both accuracy and running time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        original_shape  transformed_shape  \\\nfilename name                                                               \n2        extremely sparse JL transform               1                  1   \n3        extremely sparse JL transform               1                  1   \n5        extremely sparse JL transform               1                  1   \n\n                                        params  reduction_time  accuracy  \\\nfilename name                                                              \n2        extremely sparse JL transform       1               1         1   \n3        extremely sparse JL transform       1               1         1   \n5        extremely sparse JL transform       1               1         1   \n\n                                        train_time  score_series  \nfilename name                                                     \n2        extremely sparse JL transform           1             1  \n3        extremely sparse JL transform           1             1  \n5        extremely sparse JL transform           1             1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>original_shape</th>\n      <th>transformed_shape</th>\n      <th>params</th>\n      <th>reduction_time</th>\n      <th>accuracy</th>\n      <th>train_time</th>\n      <th>score_series</th>\n    </tr>\n    <tr>\n      <th>filename</th>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <th>extremely sparse JL transform</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <th>extremely sparse JL transform</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <th>extremely sparse JL transform</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_all_df.groupby([\"filename\", \"name\"]).count().sort_values(by=\"original_shape\").groupby(level=0).tail(1).sort_values(by=\"filename\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.819604Z",
     "start_time": "2023-07-05T07:46:40.799631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:46:40.819769Z",
     "start_time": "2023-07-05T07:46:40.803455Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
